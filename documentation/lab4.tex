\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{listings}
\usepackage{hyperref}
\lstset{
language=C,
basicstyle=\footnotesize
}
\begin{document}

\section{Lab 4}


\begin{itemize}
\item \textit{How many cores will simple.cu use, max, as written? How many SMs?}

  It will at maximum use 16 * 1 cudacores. It will run on one Streaming Multiprocessor (SM).

\item \textit{Is the calculated square root identical to what the CPU calculates?}

  It is not identical:

  \begin{lstlisting}
    0 0
    1 1
    1.4142136573791504 1.4142135623730951
    1.732050895690918  1.7320508075688772
    2 2
    2.2360682487487793 2.2360679774997898
    2.4494898319244385 2.4494897427831779
    2.6457514762878418 2.6457513110645907
    2.8284273147583008 2.8284271247461903
    3.0000002384185791 3
    3.1622776985168457 3.1622776601683795
    3.3166248798370361 3.3166247903553998
    3.4641017913818359 3.4641016151377544
    3.6055512428283691 3.6055512754639891
    3.7416574954986572 3.7416573867739413
    3.872983455657959  3.872983346207417
  \end{lstlisting}

  We can note that the GPU output is identical to that of our CPU, and Wolfram Alpah, until the 6th decimal.

\item \textit{Should we assume that this is always the case?}

  Well yes, we can assume that the results will always have the same precision. And we can assume that anything beyond that precision will be incorrect.

\item \textit{How do you calculate the index in the array, using 2-dimensional blocks?}

  Using the following code, inspired by an image from the internet with the title Accessing Matrices in Linear Memory.

  \begin{lstlisting}
    int indexX = blockIdx.x * blockDim.x + threadIdx.x;
    int indexY = blockIdx.y * blockDim.y + threadIdx.y;
    int index = indexY * N + indexX;
  \end{ltslisting}


\item \textit{What happens if you use too many threads per block?}

  Absolute and utter chaos. We've managed with 1024 threads but no more.

\item \textit{At what data size is the GPU faster than the CPU?}

  The GPU gets faster at a matrix size of 64 by 64. Though this measure does not count the time it takes to copy the data back and forth.

  \begin{lstlisting}
    < GPU execution took 0.023520 milliseconds for 32.
    > CPU execution took 0.004000 milliseconds for 32.

    < GPU execution took 0.018848 milliseconds for 64.
    > CPU execution took 0.051000 milliseconds for 64.

    < GPU execution took 0.037088 milliseconds for 128.
    > CPU execution took 0.316000 milliseconds for 128.

    < GPU execution took 0.114528 milliseconds for 256.
    > CPU execution took 0.761000 milliseconds for 256.

    < GPU execution took 0.443008 milliseconds for 512.
    > CPU execution took 4.167000 milliseconds for 512.

    < GPU execution took 1.927200 milliseconds for 1024.
    > CPU execution took 39.146000 milliseconds for 1024.
  \end{lstlisting}

  If we take the transfer times into account we get the following results:

  \begin{lstlisting}
    < GPU execution took 0.068320 milliseconds for 32.
    > CPU execution took 0.019000 milliseconds for 32.

    < GPU execution took 0.063840 milliseconds for 64.
    > CPU execution took 0.050000 milliseconds for 64.

    < GPU execution took 0.131840 milliseconds for 128.
    > CPU execution took 0.118000 milliseconds for 128.

    < GPU execution took 0.458176 milliseconds for 256.
    > CPU execution took 0.717000 milliseconds for 256.

    < GPU execution took 1.928864 milliseconds for 512.
    > CPU execution took 4.648000 milliseconds for 512.

    < GPU execution took 7.875136 milliseconds for 1024.
    > CPU execution took 40.074000 milliseconds for 1024.
  \end{lstlisting}

  With that taken into account the overtake comes at a matrix size of 128 by 128.

\item \textit{What block size seems like a good choice? Compared to what?}



\end{itemize}

\end{document}
